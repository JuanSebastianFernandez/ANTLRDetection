import re
import numpy as np
from antlr4 import CommonTokenStream
from grammars.Java.JavaParser import JavaParser
from grammars.Java.JavaParserListener import JavaParserListener
from signatures.finding_types import JavaSignatures, SENSITIVE_PATH_REGEX_GLOBAL
from typing import List, Dict, Set, Tuple


def calculate_entropy(data: bytes) -> float:
    """
    Calculate the Shannon entropy of a byte sequence.

    Args:
        data (bytes): Input byte sequence to analyze.

    Returns:
        float: Calculated entropy value. Returns 0.0 for empty input.
    """
    if not data:
        return 0.0
    occurrences = np.bincount(np.frombuffer(data, dtype=np.uint8), minlength=256)
    probabilities = occurrences / len(data)
    entropy = -np.sum([p * np.log2(p) for p in probabilities if p > 0])
    return entropy


class VestaJavaListener(JavaParserListener):
    """
    ANTLR4-based listener that statically analyzes Java source code to identify
    suspicious or potentially malicious patterns. It uses heuristic and entropy-based
    techniques to flag obfuscation, sensitive data exposure, risky method calls,
    structural anomalies, and suspicious imports.

    Attributes:
        token_stream (CommonTokenStream): Token stream from the parser.
        static_findings (List[Dict]): Collected findings from the source code.
        method_entropies (List[float]): Entropy values for each method body.
        method_sizes (List[int]): Character length of each method.
        string_entropies (List[float]): Entropy values for each string literal.
        import_count (int): Number of import and package declarations.
        class_and_method_count (int): Number of classes and methods encountered.
        has_main_method (int): 1 if a main method is found, else 0.
        _finding_ids (Set[Tuple]): Internal set to avoid duplicate findings.
        java_signatures (JavaSignatures): Reference to static rules and patterns.
    """

    def __init__(self, token_stream: CommonTokenStream) -> None:
        """
        Initializes the VestaJavaListener with a token stream.

        Args:
            token_stream (CommonTokenStream): The token stream from the parser.
        """
        self.token_stream: CommonTokenStream = token_stream
        self.static_findings: List[Dict] = []
        self.method_entropies: List[float] = []
        self.method_sizes: List[int] = []
        self.string_entropies: List[float] = []
        self.import_count: int = 0
        self.class_and_method_count: int = 0
        self.has_main_method: int = 0
        self._finding_ids: Set[Tuple] = set()
        self.java_signatures: JavaSignatures = JavaSignatures()

    def add_finding(self, finding: Dict) -> None:
        """
        Add a new finding to the result list, avoiding duplicates.

        Args:
            finding (Dict): Finding dictionary with keys 'finding_type', 'line', etc.
        """
        finding_id: Tuple = (finding['finding_type'], finding['line'], finding['description'])
        if finding_id not in self._finding_ids:
            self.static_findings.append(finding)
            self._finding_ids.add(finding_id)

    def enterClassDeclaration(self, ctx: JavaParser.ClassDeclarationContext) -> None:
        """
        Triggered upon entering a class declaration.
        Detects short or obfuscated class names.

        Args:
            ctx (JavaParser.ClassDeclarationContext): Parsing context.
        """
        self.class_and_method_count += 1
        class_name: str = ctx.identifier().getText()

        # --- Suspicious class names (e.g., obfuscated or autogenerated) ---
        if '$' in class_name or len(class_name) <= 2:
            details: Dict = self.java_signatures.NAMING_CONVENTIONS["OBFUSCATED_CLASS_SHORT_NAME"]
            finding: Dict = {
                "finding_type": details["type"],
                "description": f"Suspicious or dynamically generated class name: '{class_name}'",
                "line": ctx.start.line,
                "severity": details["severity"]
            }
            self.add_finding(finding)

    def exitMethodDeclaration(self, ctx: JavaParser.MethodDeclarationContext) -> None:
        """
        Triggered after a method declaration has been fully parsed.
        Detects suspicious naming, minimal override bodies, and calculates entropy.

        Args:
            ctx (JavaParser.MethodDeclarationContext): Parsing context.
        """
        self.class_and_method_count += 1
        method_name: str = ctx.identifier().getText()

        if method_name == 'main':
            self.has_main_method = 1

        # --- Suspiciously short method names (e.g., obfuscation) ---
        if len(method_name) <= 2:
            details: Dict = self.java_signatures.NAMING_CONVENTIONS["OBFUSCATED_METHOD_SHORT_NAME"]
            finding: Dict = {
                "finding_type": details["type"],
                "description": f"Suspiciously short method name (possible obfuscation): '{method_name}()'",
                "line": ctx.start.line,
                "severity": details["severity"]
            }
            self.add_finding(finding)

        # --- Suspicious override methods with minimal bodies ---
        is_override: bool = False
        if ctx.parentCtx and hasattr(ctx.parentCtx, 'parentCtx') and hasattr(ctx.parentCtx.parentCtx, 'modifier'):
            for mod_ctx in ctx.parentCtx.parentCtx.modifier():
                if mod_ctx.classOrInterfaceModifier() and mod_ctx.classOrInterfaceModifier().annotation() and '@Override' in mod_ctx.classOrInterfaceModifier().annotation().getText():
                    is_override = True
                    break

        if is_override and ctx.methodBody() and ctx.methodBody().block() and len(ctx.methodBody().block().blockStatement()) <= 1:
            details: Dict = self.java_signatures.STRUCTURAL_PATTERNS["SUSPICIOUS_OVERRIDE"]
            finding: Dict = {
                "finding_type": details["type"],
                "description": f"Overridden method '{method_name}' has an empty or minimal body, which could be an evasion technique.",
                "line": ctx.start.line,
                "severity": details["severity"]
            }
            self.add_finding(finding)

        start_index: int = ctx.start.tokenIndex
        stop_index: int = ctx.stop.tokenIndex
        method_text: str = self.token_stream.getText(start_index, stop_index)

        self.method_entropies.append(calculate_entropy(method_text.encode('utf-8')))
        self.method_sizes.append(len(method_text))

    def enterLiteral(self, ctx: JavaParser.LiteralContext) -> None:
        """
        Triggered when a literal (e.g., string) is encountered.
        Detects secrets, entropy in strings, and sensitive path access.

        Args:
            ctx (JavaParser.LiteralContext): Parsing context.
        """
        if ctx.STRING_LITERAL():
            string_text: str = ctx.getText()
            string_content: str = string_text[1:-1]  # Remove quotes

            # --- NEW DETECTION: Sensitive system path access ---
            if SENSITIVE_PATH_REGEX_GLOBAL.search(string_content):
                details: Dict = self.java_signatures.STRUCTURAL_PATTERNS["SENSITIVE_PATH_ACCESS"]
                finding: Dict = {
                    "finding_type": details["type"],
                    "description": f"Sensitive path access detected: '{string_content}'",
                    "line": ctx.start.line,
                    "severity": details["severity"]
                }
                self.add_finding(finding)

            if string_content:
                self.string_entropies.append(calculate_entropy(string_content.encode('utf-8')))

            for keyword, details in self.java_signatures.STRING_KEYWORDS.items():
                if re.search(re.escape(keyword), string_content, re.IGNORECASE):
                    self.add_finding({
                        "finding_type": details["type"],
                        "description": f"Possible secret/credential found in string literal containing '{keyword}'",
                        "line": ctx.start.line,
                        "severity": details["severity"]
                    })

    def enterMethodCall(self, ctx: JavaParser.MethodCallContext) -> None:
        """
        Detects use of potentially dangerous method calls.

        Args:
            ctx (JavaParser.MethodCallContext): Parsing context.
        """
        call_text: str = ctx.getText()
        for pattern, details in self.java_signatures.METHOD_CALLS.items():
            if call_text in pattern:
                self.add_finding({
                    "finding_type": details["type"],
                    "description": f"Use of potentially dangerous method call detected: '{pattern}'",
                    "line": ctx.start.line,
                    "severity": details["severity"]
                })
                break

    def enterCreator(self, ctx: JavaParser.CreatorContext) -> None:
        """
        Detects use of 'new File(".")', which may indicate self-aware code.

        Args:
            ctx (JavaParser.CreatorContext): Parsing context.
        """
        if ctx.createdName().getText() == 'File':
            if ctx.classCreatorRest() and ctx.classCreatorRest().arguments().getText() == '(".")':
                details: Dict = self.java_signatures.STRUCTURAL_PATTERNS["SELF_AWARE_CODE_FILE_DOT"]
                self.add_finding({
                    "finding_type": details["type"],
                    "description": "Code accesses the current directory via 'new File(\".\")', which may precede self-modification.",
                    "line": ctx.start.line,
                    "severity": details["severity"]
                })

    def enterImportDeclaration(self, ctx: JavaParser.ImportDeclarationContext) -> None:
        """
        Detects suspicious imports based on predefined patterns.

        Args:
            ctx (JavaParser.ImportDeclarationContext): Parsing context.
        """
        self.import_count += 1
        import_text: str = ctx.qualifiedName().getText()
        for pattern, details in self.java_signatures.IMPORTS.items():
            if import_text.startswith(pattern):
                self.add_finding({
                    "finding_type": details["type"],
                    "description": f"Suspicious import detected: '{import_text}'. Indicates: {details['desc']}",
                    "line": ctx.start.line,
                    "severity": details["severity"]
                })

    def enterPackageDeclaration(self, ctx: JavaParser.PackageDeclarationContext) -> None:
        """
        Increments import count (used in entropy vector), even for package declarations.

        Args:
            ctx (JavaParser.PackageDeclarationContext): Parsing context.
        """
        self.import_count += 1

    def enterCatchClause(self, ctx: JavaParser.CatchClauseContext) -> None:
        """
        Detects empty catch blocks, which may hide critical security issues.

        Args:
            ctx (JavaParser.CatchClauseContext): Parsing context.
        """
        if ctx.block() and not ctx.block().blockStatement():
            details: Dict = self.java_signatures.STRUCTURAL_PATTERNS["EMPTY_CATCH_BLOCK"]
            self.add_finding({
                "finding_type": details["type"],
                "description": "Empty catch block detected. Swallowing exceptions can mask critical security issues.",
                "line": ctx.start.line,
                "severity": details["severity"]
            })

    def get_analysis_report(self) -> Dict:
        """
        Generates a final analysis report including statistical features and detected findings.

        Returns:
            Dict: A dictionary containing:
                - 'feature_vector': Feature values useful for ML models or heuristics.
                - 'static_findings': List of detected static issues in the code.
        """
        sections_max_entropy: float = np.max(self.method_entropies) if self.method_entropies else 0.0
        sections_min_entropy: float = np.min(self.method_entropies) if self.method_entropies else 0.0
        sections_min_virtualsize: float = np.min(self.method_sizes) if self.method_sizes else 0.0
        resources_min_entropy: float = np.min(self.string_entropies) if self.string_entropies else 0.0

        feature_vector: Dict[str, float] = {
            'SectionsMaxEntropy': sections_max_entropy,
            'SizeOfStackReserve': float(self.class_and_method_count),
            'SectionsMinVirtualsize': float(sections_min_virtualsize),
            'ResourcesMinEntropy': resources_min_entropy,
            'MajorLinkerVersion': 1.0,
            'SizeOfOptionalHeader': float(self.import_count),
            'AddressOfEntryPoint': float(self.has_main_method),
            'SectionsMinEntropy': sections_min_entropy,
            'MinorOperatingSystemVersion': 0.0,
            'SectionAlignment': 0.0,
            'SizeOfHeaders': float(self.import_count),
            'LoaderFlags': 0.0,
        }

        return {
            "feature_vector": feature_vector,
            "static_findings": self.static_findings
        }
